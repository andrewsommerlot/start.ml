'pr_day_GFDL-ESM2M_historical_r1i1p1_19810101-19851231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19810101-19851231.nc' 'MD5' 'c43d3d8b90bec11bc97e522ee47e5863',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19460101-19501231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19460101-19501231.nc' 'MD5' 'b0caacb161933222ddda327ce64f266a',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19610101-19651231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19610101-19651231.nc' 'MD5' '3486bf68f6d85afc77e44d58399559fa',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19510101-19551231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19510101-19551231.nc' 'MD5' 'cf945c10ed09f14ab276b6b3c0bbe6f9',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19410101-19451231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19410101-19451231.nc' 'MD5' '502b2aaaeee7ad8354da42dbacdd1e3b',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19760101-19801231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19760101-19801231.nc' 'MD5' 'a6898c310aec36690d89760ba0c35625',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19710101-19751231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19710101-19751231.nc' 'MD5' '3bf85c97eb12990991e9c83dcaa4fc0b',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19660101-19701231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19660101-19701231.nc' 'MD5' '90db5b357cd34c72a02b63d487289e75',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19560101-19601231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19560101-19601231.nc' 'MD5' '3155fbb67ee1d457f9106dc217ed004e',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19360101-19401231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19360101-19401231.nc' 'MD5' 'f838357fc0c5ba4960dcf66502bd8c61',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19010101-19051231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19010101-19051231.nc' 'MD5' '0f4254b4e39f173a37b7547df5d2738a',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18960101-19001231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18960101-19001231.nc' 'MD5' '84363a7e1712ea850508ae0638276882',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19310101-19351231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19310101-19351231.nc' 'MD5' 'b51773fc8d3b0ad9bc01d1bbd1d09f3d',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19260101-19301231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19260101-19301231.nc' 'MD5' '579f54b42e093ae4f62944efa1caa55c',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19110101-19151231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19110101-19151231.nc' 'MD5' 'adde52b8aa2e9eddd1637e21ab560682',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18910101-18951231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18910101-18951231.nc' 'MD5' 'b630a842640aac858e0ebcbe95697ea7',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19210101-19251231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19210101-19251231.nc' 'MD5' '16bc8d51c93d1caa89002f44be22e932',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19160101-19201231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19160101-19201231.nc' 'MD5' '4929768b6d0ea9e6c5d86f9aa64fd583',
'pr_day_GFDL-ESM2M_historical_r1i1p1_19060101-19101231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19060101-19101231.nc' 'MD5' '2cfaede74fd977d2f9e21c17ad808aa0',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18710101-18751231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18710101-18751231.nc' 'MD5' '18c6f8585f11e511c9112a355bef33d5',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18610101-18651231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18610101-18651231.nc' 'MD5' '12d7d18b37697fc36cae3e18e9e32a85',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18810101-18851231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18810101-18851231.nc' 'MD5' 'c435068adf53003c3ef69fbf8ccb3b1a',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18860101-18901231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18860101-18901231.nc' 'MD5' '1a23376b01fabe6522db73956217e6e3',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18760101-18801231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18760101-18801231.nc' 'MD5' 'ed78188fbf7e9762ced7331c53e254a9',
'pr_day_GFDL-ESM2M_historical_r1i1p1_18660101-18701231.nc' 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_18660101-18701231.nc' 'MD5' 'ede1da2ba9a99db37194610814013c9c')
file_split = strsplit(file_loc, '/')
file_loc = 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19860101-19901231.nc'
file_split = strsplit(file_loc, '/')
file_split
file_here = file_split[length(file_split)]
file_here
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(uurl = file_loc, destfile = paste(auto_down, file_hre, sep = '/'))
download.file(url = file_loc, destfile = paste(auto_down, file_hre, sep = '/'))
download.file(url = file_loc, destfile = paste(save_loc, file_hre, sep = '/'))
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
file_loc
download.file(file_loc)
download.file(file_loc, dest_file = 'C:/Users/Andy/Desktop')
download.file(file_loc, destfile = 'C:/Users/Andy/Desktop')
download.file(file_loc, destfile = 'C:/Users/Andy/Desktop/auto_down')
file_here
length(file_split)
file_here = file_split[length(file_split[[1]])]
file_here
file_here = file_split[length(file_split[1])]
file_here
file_here[16]
file_here[[1]][16]
length(file_split[[1]])
file_here = file_split[[1]][length(file_split[[1]])]
file_here
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
file_loc = 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19860101-19901231.nc'
file_split = strsplit(file_loc, '/')
file_here = file_split[[1]][length(file_split[[1]])]
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
file_list
file_loc = 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-CM3/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19860101-19901231.nc'
file_split = strsplit(file_loc, '/')
file_here = file_split[[1]][length(file_split[[1]])]
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
file_loc = 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-CM3/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-CM3_historical_r1i1p1_19860101-19901231.nc'
file_split = strsplit(file_loc, '/')
file_here = file_split[[1]][length(file_split[[1]])]
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
file_loc = 'http://esgdata.gfdl.noaa.gov/thredds/fileServer/gfdl_dataroot/NOAA-GFDL/GFDL-ESM2M/historical/day/atmos/day/r1i1p1/v20110601/pr/pr_day_GFDL-ESM2M_historical_r1i1p1_19860101-19901231.nc'
file_split = strsplit(file_loc, '/')
file_here = file_split[[1]][length(file_split[[1]])]
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
download.file(url = file_loc, destfile = paste(save_loc, file_here, sep = '/'))
library(jsonlite)
t = fromJSON('C:/Users/Andy/Desktop/auto_down/test/.json')
t = stream_in('C:/Users/Andy/Desktop/auto_down/test/.json', handler = NULL, pagesize = 500, verbose = TRUE, ...)
t = stream_in('C:/Users/Andy/Desktop/auto_down/test.json', handler = NULL, pagesize = 500, verbose = TRUE, ...)
t = stream_in('C:/Users/Andy/Desktop/auto_down/test.json', handler = NULL, pagesize = 500, verbose = TRUE)
t = stream_in(file.con('C:/Users/Andy/Desktop/auto_down/test.json'), handler = NULL, pagesize = 500, verbose = TRUE)
t = stream_in(filecon('C:/Users/Andy/Desktop/auto_down/test.json'), handler = NULL, pagesize = 500, verbose = TRUE)
t = stream_in(file('C:/Users/Andy/Desktop/auto_down/test.json'), handler = NULL, pagesize = 500, verbose = TRUE)
t = stream_in(file('C:/Users/Andy/Desktop/auto_down/test.json'), handler = NULL, pagesize = 500, verbose = TRUE)
c = file('C:/Users/Andy/Desktop/auto_down/test.json')
c
t = stream_in(c, handler = NULL, pagesize = 500, verbose = TRUE)
library(rjson)
install.packages('rjson')
library(rjson)
rd = readLines('C:/Users/Andy/Desktop/auto_down/test.json')
rd = readLines('C:/Users/Andy/Desktop/auto_down/test.json')
rd
t = fromJSON(rd)
fromJSON
rd
detach(rjson)
detach("package:rjson", unload=TRUE)
rd = readLines('C:/Users/Andy/Desktop/auto_down/test.json')
t = fromJSON(rd)
t
class(t)
str(list)
str(t)
t[1]
t[1][2]
t[[1]][2]
t[[1]][3]
t[[1]][4]
t[[1]][5]
t[[1]][6]
do.call('rbind', t[[1]])
do.call('cbind', t[[1]])
df = do.call('cbind', t[[1]])
df$urls[1]
df$urls\
df$urls
class(df)
df = data.frame(do.call('cbind', t[[1]]))
head(df)
df$urls[1]
class(df$urls[1])
str(df)
head(df[,1:3])
head(df[,1:4])
head(df[,1:5])
View(df)
View(ft)
View(ft)
View(df)
head(df[,1:5])
model = 'GFDL-ESM2M'
scenario = 'historical'
realization = 'r1i1p1'
variable = 'pr'
which(df[,2] == model & df[,3] == scenario & df[,4] == realization & df[,5] == variable)
rowid = which(df[,2] == model & df[,3] == scenario & df[,4] == realization & df[,5] == variable)
rowid
file_list = df[rowid,6]
file_list
variable = 'tasmin'
rowid = which(df[,2] == model & df[,3] == scenario & df[,4] == realization & df[,5] == variable)
rowid
file_list = df[rowid,6]
file_split = lapply(file_list, split = '/')
file_split = lapply(file_list, FUN = strsplit, split = '/')
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_split
file_here = file_split[[1]][length(file_split[[1]])]
file_here
file_here = file_split[[1]][length(file_split[[1]])]
file_here
file_split[[1]]
file_here = file_split[[1]][1][length(file_split[[1]][1])]
file_split
file_here
file_split[[1]][1][16]
file_split[[1]][[1]][16]
file_here = file_split[[1]][[1]][length(file_split[[1]][[1]])]
file_here
ExtractSubset
do_subset_dflt
file_split
lapply(file_split, `[[`, 16)
lapply(file_split, '[[', 1)
length(file_split[[1]][[1]])
lapply(lapply[[1]], '[[', length(file_split[[1]][[1]]))
lapply(file_list[[1]], '[[', length(file_split[[1]][[1]]))
lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_here
file_list
file_loc
file_here
file_list
download.file(url = file_list, destfile = paste(save_loc, file_here, sep = '/'))
lapply(file_list, FUN = 'download.file', destfile = paste(save_loc, file_here, sep = '/'))
file_list[2]
file_list[1]
unlist(file_list)
class(file_list)
file_here = unlist(file_here)
file_here
class(file_here)
fo;e_list
file_list
class(file_list)
str(file_LIST)
str(file_list)
file_list = df[rowid,6]
file_list = unlist(file_list)
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
str(file_here)
file_here
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_here
file_list = df[rowid,6]
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_here
rd = readLines('C:/Users/Andy/Desktop/auto_down/test.json')
t = fromJSON(rd)
df = data.frame(do.call('cbind', t[[1]]))
# search the df for
model = 'GFDL-ESM2M'
scenario = 'historical'
realization = 'r1i1p1'
variable = 'tasmin'
rowid = which(df[,2] == model & df[,3] == scenario & df[,4] == realization & df[,5] == variable)
file_list = df[rowid,6]
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_here
str(file_here)
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
lapply(file_list, FUN = 'download.file', destfile = paste(save_loc, file_here, sep = '/'))
file_list
file_list = unlist(file_list)
file_list
lapply(file_list, FUN = 'download.file', destfile = paste(save_loc, file_here, sep = '/'))
download
download.nc
file_here
file_list
file_here[2]
file_here[3]
file_here[4]
file_here[6]
file_here[7]
file_list[1]
file_list[2]
unlist(file_here)
file_here = unlist(file_here)
file_here
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
locs
locs[[1]][1]
locs[[1]][2]
locs = mapply(file_list, file_here, SIMPLIFY=FALSE)
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
download.nc = function(locs, save_loc){
download.file(url = locs[1], destfile = paste(save_loc, locs[2], sep = '/'))
}
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
lapply(locs, FUN = 'download.nc', destfile = paste(save_loc, file_here, sep = '/'))
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
x1 <- runif(1, 5.0, 7.5)
x1
x1 <- runif(1, 100000000, 900000000)
x1
x1 <- runif(1, 100000000, 900000000)
x1
tmp =  paste(runif(1, 100000000, 900000000), '_tmp_.json'
tmp = paste(runif(1, 100000000, 900000000), '_tmp_.json')
tmp
tmp = paste(runif(1, 100000000, 900000000), '_tmp_.json', sep = '')
tmp
runif(1, 100000000, 900000000)
runif(1, 100000000, 900000000)
runif(1, 100000000, 900000000)
runif(1, 100000000, 900000000)
tmp = paste(digits(runif(1, 100000000, 900000000),0), '_tmp_.json', sep = '')
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
tmp
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
tmp
delete
file.remove
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
load_epsg_catalog()
data
load
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
load(epsg_catalog)
}
load_epsg_catalog()
epsg_catalog = load_epsg_catalog()
dest
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
epsg_catalog = load_epsg_catalog()
epsg_catalog
class(epsg_catalog)
view
str(epsg_catalog)
library(jsonlite)
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
# short function for lapply in get_epsg_nc
download.nc = function(locs, save_loc){
download.file(url = locs[1], destfile = paste(save_loc, locs[2], sep = '/'))
}
# download nc files from epsg based on user query
get_cmip5_nc = function(model, scenario, realization, variable, save_loc){
epsg_catalog = load_epsg_catalog()
rowid = which(epsg_catalog[,2] == model & epsg_catalog[,3] == scenario & epsg_catalog[,4] == realization & epsg_catalog[,5] == variable)
file_list = epsg_catalog[rowid,6]
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_list = unlist(file_list)
file_here = unlist(file_here)
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
}
model = 'GFDL-ESM2M'
scenario = 'historical'
realization = 'r1i1p1'
variable = 'tasmin'
variable = 'tasmax'
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
str(str)
str(df)
head(df[,1:5])
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
# short function for lapply in get_epsg_nc
download.nc = function(locs, save_loc){
download.file(url = locs[1], destfile = paste(save_loc, locs[2], sep = '/'))
}
# download nc files from epsg based on user query
get_cmip5_nc = function(model, scenario, realization, variable, save_loc){
epsg_catalog = load_epsg_catalog()
rowid = which(epsg_catalog[,2] == model & epsg_catalog[,3] == scenario & epsg_catalog[,4] == realization & epsg_catalog[,5] == variable)
file_list = unlist(epsg_catalog[rowid,6])
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = unlist(lapply(file_split[[1]], '[[', length(file_split[[1]][[1]])))
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
}
library(jsonlite)
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
# short function for lapply in get_epsg_nc
download.nc = function(locs, save_loc){
download.file(url = locs[1], destfile = paste(save_loc, locs[2], sep = '/'))
}
# download nc files from epsg based on user query
get_cmip5_nc = function(model, scenario, realization, variable, save_loc){
epsg_catalog = load_epsg_catalog()
rowid = which(epsg_catalog[,2] == model & epsg_catalog[,3] == scenario & epsg_catalog[,4] == realization & epsg_catalog[,5] == variable)
file_list = unlist(epsg_catalog[rowid,6])
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = unlist(lapply(file_split[[1]], '[[', length(file_split[[1]][[1]])))
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
}
model = 'GFDL-ESM2M'
scenario = 'historical'
realization = 'r1i1p1'
variable = 'tasmax'
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
model = 'GFDL-ESM2M'
scenario = 'historical'
realization = 'r1i1p1'
variable = 'tasmax'
save_loc = 'C:/Users/Andy/Desktop/auto_down/data'
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
library(jsonlite)
load_epsg_catalog = function(){
tmp = paste(round(runif(1, 100000000, 900000000)), '_tmp_.json', sep = '')
dest = paste(getwd(), tmp, sep = '/')
download.file(url = 'http://zachary.bse.vt.edu/static/epsg_catalog.json', destfile = dest)
rd = readLines(dest)
t = fromJSON(rd)
epsg_catalog = data.frame(do.call('cbind', t[[1]]))
file.remove(dest)
return(epsg_catalog)
}
# short function for lapply in get_epsg_nc
download.nc = function(locs, save_loc){
download.file(url = locs[1], destfile = paste(save_loc, locs[2], sep = '/'))
}
# download nc files from epsg based on user query
get_cmip5_nc = function(model, scenario, realization, variable, save_loc){
epsg_catalog = load_epsg_catalog()
rowid = which(epsg_catalog[,2] == model & epsg_catalog[,3] == scenario & epsg_catalog[,4] == realization & epsg_catalog[,5] == variable)
file_list = epsg_catalog[rowid,6]
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_list = unlist(file_list)
file_here = unlist(file_here)
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
}
get_cmip5_nc(model = model, scenario = scenario, realization = realization, variable = variable, save_loc = save_loc)
locs
epsg_catalog = load_epsg_catalog()
rowid = which(epsg_catalog[,2] == model & epsg_catalog[,3] == scenario & epsg_catalog[,4] == realization & epsg_catalog[,5] == variable)
rowid
file_list = epsg_catalog[rowid,6]
file_split = lapply(file_list, FUN = 'strsplit', split = '/')
file_here = lapply(file_split[[1]], '[[', length(file_split[[1]][[1]]))
file_list = unlist(file_list)
file_here = unlist(file_here)
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
locs
locs[1]
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
inp = locs[3]
inp
download.nc(inp[1], inp[2])
inp[1]
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
locs
locs[1]
locs[[[1]][1]
locs[[1]][1]
file_list = unlist(file_list)
file_list
locs = mapply(c, file_list, file_here, SIMPLIFY=FALSE)
locs
locs[3]
lapply(locs, FUN = 'download.nc', save_loc = save_loc)
library(h2o)
install.packages(c("manipulate", "Matrix", "Rcpp"))
library(h2o)
library(h2oEnsemble)
# start decent size (more ram than needed for this)
df1 <- h2o.importFile(path = normalizePath("../10-4-16/numerai_training_data.csv"))
#df2 <- h2o.importFile(path = "/Users/Andy/Desktop/numerai/9-21-16/numerai_training_data.csv")
test_real <- h2o.importFile(path = normalizePath("../10-4-16/numerai_tournament_data.csv"))
y <- "target"
df1[,y] <- as.factor(df1[,y])
h2o.init(nthreads=-1, max_mem_size="16G")
install.packages('h2o')
install.packages('h2o')
library(h2o)
install.packages('h2o')
install.packages('h2o')
install.packages("h2o", source)
install.packages("h2o", type =source)
install.packages("h2o", type = "source")
library(h2o)
library(h2o)
library(Metrics)
h2o.init(nthreads=-1, max_mem_size="6G")
h2o.removeAll()
h2o.removeAll()
h2o.shutdown(prompt = FALSE)
library(installr)
updateR()
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
setwd("C/Users/Andy/Desktop/r-package/startml")
setwd("C:/Users/Andy/Desktop/r-package/startml")
create("startml")
setwd("C:/Users/Andy/Desktop/r-package/startml")
