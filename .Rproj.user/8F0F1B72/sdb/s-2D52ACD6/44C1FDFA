{
    "collab_server" : "",
    "contents" : "#' select_models\n#'\n#' Caculate performance metrics from models on new data. Depends on Metrics package.\n#' @param prediction_list List object of H2O frames containing predictions.\n#' No Default.\n#' @param test H2O frame object containing labeled data for model evaluation.\n#' No Default.\n#' @param eval_metric Character object one of logloss, MSE, RMSE, MAE, AUC, or mean_per_class_error.\n#' @param y Character object of length 1 identifying the column name of the target variable. No Default.\n#' @return List object same length as prediction_list containing performance of each model on test input with selected metric.\n#' @export\n# get test holdout metrics from models # depends on Metrics package for now\ntest_metric_h2o <- function(prediction_list, test, eval_metric, y) {\n  if(eval_metric == \"AUC\" | eval_metric == \"logloss\") {\n    predictions <- lapply(prediction_list, function(x)x[,3])\n  } else {\n    predictions <- lapply(prediction_list, function(x)x[,1])\n  }\n  actual <- test[,y]\n  if(eval_metric == \"logloss\") {\n    metric <- lapply(predictions, FUN = logLoss, actual = actual)\n  } else if(eval_metric == \"MSE\") {\n    metric <- lapply(predictions, FUN = mse, actual = actual)\n  } else if(eval_metric == \"RMSE\") {\n    metric <- lapply(predictions, FUN = rmse, actual = actual)\n  } else if(eval_metric == \"MAE\") {\n    metric <- lapply(predictions, FUN = mae, actual = actual)\n  } else if(eval_metric == \"AUC\") {\n    metric <- lapply(predictions, FUN = auc, actual = actual)\n  } else if(eval_metric == \"mean_per_class_error\") {\n    metric <- lapply(predictions, FUN = ce, actual = actual)\n  }else if(eval_metric == \"RMSLE\") {\n    metric <- lapply(predictions, FUN = rmsle, actual = actual)\n  } else {\n    stop(\"Choose an eval metric: logloss, MSE, RMSE, MAE, AUC, mean_per_class_error\")\n  }\n  metric\n}\n",
    "created" : 1496011524565.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3153945181",
    "id" : "44C1FDFA",
    "lastKnownWriteTime" : 1496012510,
    "last_content_update" : 1496012510995,
    "path" : "C:/Users/Andy/Desktop/r-package/startml/R/test-metric.R",
    "project_path" : "R/test-metric.R",
    "properties" : {
    },
    "relative_order" : 20,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}