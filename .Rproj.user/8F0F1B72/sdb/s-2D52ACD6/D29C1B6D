{
    "collab_server" : "",
    "contents" : "#' gbm_autogrid\n#'\n#' gbm_autogrid is a wrapper employing built-in settings to run grid search hyper parameter optimizations on gradient boosted machine algorithm.\n#'\n#' @param train H2O frame object containing labeled data for model training.\n#' No Default.\n#' @param valid H2O frame object containing labeled data for model validation.\n#' No Default.\n#' @param y Character object of length 1 identifying the column name of the target variable. No Default.\n#' @param x Character object of length 1 or more identifying the column name(s) of the input variables. No Default.\n#' @param folds Character object defining number of folds for xval. Default is NULL and currently is not implemented.\n#' @param gbm_runtime_secs Numeric object defining total number of seconds the hyper parameter grid search will run.\n#' @param gbm_stopping_rounds Numeric object defining maximum number of training rounds an individual deep learning model not improving will continue to run. Default is 10.\n#' @param gbm_stopping_tolerance Numeric object which sets the mimmum loss funciton improvement for a training iteration to be considered an improvement. Defulat is 1E-5.\n#' @param gbm_min_depth Numeric object which sets the mimmum loss funciton improvement for a training iteration to be considered an improvement. Defulat is 1E-5.\n#' @param gbm_max_depth Numeric object which sets the maximum tree depth for all gbm models. Defulat is 7.\n#' @param grid_strategy Character object default and only current supported option is \"randomDiscrete\"\n#' @param eval_metric Character object defining evaluation metric for training. Defualt is \"AUTO\" and uses built-in H2O automatic choice for target data type.\n#' @param wd Character object defining file path where dl_models folder will be created and deep learning models saved. Defaults to current working directory.\n#' @return List object containing H2O model objects. Additionally saves h2o models as re-loadable text files in wd/gbm_models folder.\n#' @export\ngbm_autogrid <- function(train,\n                         valid,\n                         y,\n                         x,\n                         eval_metric = \"AUTO\",\n                         wd = getwd(),\n                         folds = NULL,\n                         gbm_min_depth = 1,\n                         gbm_max_depth = 7,\n                         gbm_runtime_secs = 10,\n                         gbm_stopping_rounds = 10,\n                         gbm_stopping_tolerance = 1e-5,\n                         grid_strategy = \"RandomDiscrete\") {\n\n  cat(\"Training Gradient Boosting Models\\n\")\n  #============================================================\n  # needs to be reviewed for smart values and changable...\n  # score_tree_interval = c(2, 5, 10),\n  gbm_parameter_search = list(\n    max_depth = seq(gbm_min_depth, gbm_max_depth, 1),\n    sample_rate = seq(0.2, 1, 0.01),\n    col_sample_rate = seq(0.2,0.9,1),\n    col_sample_rate_per_tree = seq(0.2, 0.9, 1),\n    col_sample_rate_change_per_level = seq(0.9,1.1,0.01),\n    min_rows = 2^seq(0,log2(nrow(train))-1,1),\n    nbins = 2^seq(4,10,1),\n    nbins_cats = 2^seq(4,12,1),\n    min_split_improvement = c(0,1e-8,1e-6,1e-4),\n    learn_rate = c(0.1, 0.01, 0.001),\n    learn_rate_annealing = c(0.1, 0.5, .99), ## check this for reasonableness\n    histogram_type = c(\"UniformAdaptive\",\"QuantilesGlobal\",\"RoundRobin\")\n  )\n\n  gbm_search_criteria = list(\n    strategy = grid_strategy,\n    max_runtime_secs = gbm_runtime_secs,\n    stopping_rounds =  gbm_stopping_rounds,\n    stopping_tolerance = gbm_stopping_tolerance,\n    stopping_metric = eval_metric,\n    seed = 1234 # needs to be changable\n  )\n\n  # needs be removed first for iterating within same session\n  h2o.rm(\"gbm\")\n  gbm_random_grid <- h2o.grid(algorithm = \"gbm\",\n                              grid_id = \"gbm\", # this causes failure on repreat runs, but automatic names give huge model ids\n                              x = x,\n                              y = y,\n                              training_frame = train,\n                              validation_frame = valid,\n                              ntrees = 4000, # has to be adjustable\n                              hyper_params = gbm_parameter_search,\n                              search_criteria = gbm_search_criteria,\n                              seed = 1234)\n  #====================================\n  #gbm_grid <- h2o.getGrid(\"gbm\") # already returns grid\n\n  # write out the models to disk\n  gbm_path <- paste(wd, \"/gbm_models\", sep = \"\")\n  gbm_model_files <- sapply(gbm_random_grid@model_ids, function(m) h2o.saveModel(h2o.getModel(m), path = gbm_path, force = TRUE))\n\n  # print out\n  cat(paste(\"gbm Models Saved To:\\n\", gbm_path, \"\\n\\n\"))\n  gbm_random_grid\n}\n",
    "created" : 1496000715907.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2954302158",
    "id" : "D29C1B6D",
    "lastKnownWriteTime" : 1496011120,
    "last_content_update" : 1496011120828,
    "path" : "C:/Users/Andy/Desktop/r-package/startml/R/gbm-autogrid.R",
    "project_path" : "R/gbm-autogrid.R",
    "properties" : {
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}